apiVersion: v1
kind: Pod
metadata:
  name: logstash-es-day3
spec:
  nodeSelector:
    cloud.google.com/gke-nodepool: rally-nodes
  containers:
  - name: logstash
    image: ugosan/logstash-custom:8.8.2-dev
    imagePullPolicy: Always
    resources:
        limits:
          memory: "2Gi"
          cpu: "2500m"
        requests: 
          memory: "1Gi"
          cpu: "300m"
    env: 
      - name: GCP_FILE_MATCH_REGEX
        value: "2023-01-03/.*\\.gz"
      - name: USERNAME
        value: "elastic"
      - name: PASSWORD
        valueFrom:
          secretKeyRef:
            name: es-cluster-es-elastic-user
            key: elastic
    volumeMounts:
      - name: config-volume
        mountPath: /usr/share/logstash/config
      - name: tmp-volume
        mountPath: /tmp/logstash/
      - name: pipeline-volume
        mountPath: /tmp/logstash/pipelines
      - name: credentials
        mountPath: /tmp/logstash/credentials
  volumes:  
  - name: tmp-volume
    emptyDir: {}
  - name: config-volume
    configMap:
      name: logstash-configmap-es
      items:
        - key: pipelines.yml
          path: pipelines.yml
        - key: logstash.yml
          path: logstash.yml
  - name: credentials
    secret:
      secretName: google-cloud-storage-credentials
      items:
      - key: encoded
        path: credentials.json
  - name: pipeline-volume
    configMap:
      name: logstash-configmap-es
      items:
        - key: big5-benchmark.conf
          path: big5-benchmark.conf

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-configmap-es
data:
  pipelines.yml: |
    - pipeline.id: big5-benchmark
      path.config: "/tmp/logstash/pipelines/big5-benchmark.conf"
      pipeline.batch.size: 4000
  logstash.yml: |
    log.level: info
  
  big5-benchmark.conf: |
    input {
        google_cloud_storage {
            bucket_id => "my-benchmarks-datasets"
            file_matches => "${GCP_FILE_MATCH_REGEX}"
            processed_db_path => "/tmp/logstash/processed_db/db"
            codec => json_lines
            json_key_file => "/tmp/logstash/credentials/credentials.json"
            interval => 300
            metadata_key => "x-goog-meta-benchmarks-elasticsearch-22-july"
        }
    }

    filter {

        mutate {
            remove_field => ["path", "@version", "host", "data_stream"]
            copy => {
              "[@metadata][gcs][name]" => "[meta][file]"
            }
        }

    }

    output {

        elasticsearch {
            hosts => "https://es-cluster-es-http.default.svc.cluster.local:9200"
            ssl => true
            ssl_certificate_verification => false
            document_id => "%{[@metadata][gcs][line_id]}"

            user => "${USERNAME}"
            password => "${PASSWORD}"

            data_stream => "true"
            data_stream_type => "logs"
            data_stream_dataset => "benchmark"
            data_stream_namespace => "dev"
        }

    }
